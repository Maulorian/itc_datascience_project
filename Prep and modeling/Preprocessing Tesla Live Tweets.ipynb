{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('live_tweets_tesla.csv', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1363244173047062535</td>\n",
       "      <td>1363206516673765376</td>\n",
       "      <td>2021-02-20 23:48:33 IST</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>23:48:33</td>\n",
       "      <td>200</td>\n",
       "      <td>3245686636</td>\n",
       "      <td>astute_ryan</td>\n",
       "      <td>Ryan ‚öæÔ∏è</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'NaeimKhanjani', 'name': 'Nae...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1363244165358829569</td>\n",
       "      <td>1363140009814069249</td>\n",
       "      <td>2021-02-20 23:48:31 IST</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>23:48:31</td>\n",
       "      <td>200</td>\n",
       "      <td>219270801</td>\n",
       "      <td>andaluzajasp</td>\n",
       "      <td>Inma Serrano üá™üá∏üïäüåç</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'ReinaldoDMM', 'name': 'Reina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1363244049403117579</td>\n",
       "      <td>1363244049403117579</td>\n",
       "      <td>2021-02-20 23:48:03 IST</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>23:48:03</td>\n",
       "      <td>200</td>\n",
       "      <td>1037650963476172800</td>\n",
       "      <td>mrfib011235813</td>\n",
       "      <td>MrFib 011235813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1363244015718694914</td>\n",
       "      <td>1362515242438262791</td>\n",
       "      <td>2021-02-20 23:47:55 IST</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>23:47:55</td>\n",
       "      <td>200</td>\n",
       "      <td>1556630828</td>\n",
       "      <td>redneurons</td>\n",
       "      <td>Ko…ói üêå #FarmersProtest #EndSARS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'TheAfricaReport', 'name': 'T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1363243944721711104</td>\n",
       "      <td>1363243944721711104</td>\n",
       "      <td>2021-02-20 23:47:38 IST</td>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>23:47:38</td>\n",
       "      <td>200</td>\n",
       "      <td>816835464728604673</td>\n",
       "      <td>electricjesus_</td>\n",
       "      <td>Matthew Raymond Julian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126820</th>\n",
       "      <td>1361712293428486146</td>\n",
       "      <td>1361704766577991683</td>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>18:21:24</td>\n",
       "      <td>200</td>\n",
       "      <td>1354817195902033929</td>\n",
       "      <td>juanpab06662684</td>\n",
       "      <td>juan pablo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'elonmusk', 'name': 'Elon Mus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126821</th>\n",
       "      <td>1361712292086181889</td>\n",
       "      <td>1361704766577991683</td>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>18:21:24</td>\n",
       "      <td>200</td>\n",
       "      <td>3182022667</td>\n",
       "      <td>dig_deeper1</td>\n",
       "      <td>Carlos Gonzalez</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'LunchWithElon', 'name': 'Hri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126822</th>\n",
       "      <td>1361712291989839873</td>\n",
       "      <td>1361704766577991683</td>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>18:21:24</td>\n",
       "      <td>200</td>\n",
       "      <td>836754254861856768</td>\n",
       "      <td>drowningrockets</td>\n",
       "      <td>Icylder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'elonmusk', 'name': 'Elon Mus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126823</th>\n",
       "      <td>1361712291583033346</td>\n",
       "      <td>1361704766577991683</td>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>18:21:24</td>\n",
       "      <td>200</td>\n",
       "      <td>1333857184074043392</td>\n",
       "      <td>2goodhz</td>\n",
       "      <td>2goodhz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'elonmusk', 'name': 'Elon Mus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126824</th>\n",
       "      <td>1361712290702196740</td>\n",
       "      <td>1361704766577991683</td>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>18:21:24</td>\n",
       "      <td>200</td>\n",
       "      <td>1346885101297291264</td>\n",
       "      <td>sk61693745</td>\n",
       "      <td>SK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'Tesla', 'name': 'Tesla', 'id...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126825 rows √ó 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id      conversation_id               created_at  \\\n",
       "0       1363244173047062535  1363206516673765376  2021-02-20 23:48:33 IST   \n",
       "1       1363244165358829569  1363140009814069249  2021-02-20 23:48:31 IST   \n",
       "2       1363244049403117579  1363244049403117579  2021-02-20 23:48:03 IST   \n",
       "3       1363244015718694914  1362515242438262791  2021-02-20 23:47:55 IST   \n",
       "4       1363243944721711104  1363243944721711104  2021-02-20 23:47:38 IST   \n",
       "...                     ...                  ...                      ...   \n",
       "126820  1361712293428486146  1361704766577991683  2021-02-16 18:21:24 IST   \n",
       "126821  1361712292086181889  1361704766577991683  2021-02-16 18:21:24 IST   \n",
       "126822  1361712291989839873  1361704766577991683  2021-02-16 18:21:24 IST   \n",
       "126823  1361712291583033346  1361704766577991683  2021-02-16 18:21:24 IST   \n",
       "126824  1361712290702196740  1361704766577991683  2021-02-16 18:21:24 IST   \n",
       "\n",
       "              date      time  timezone              user_id         username  \\\n",
       "0       2021-02-20  23:48:33       200           3245686636      astute_ryan   \n",
       "1       2021-02-20  23:48:31       200            219270801     andaluzajasp   \n",
       "2       2021-02-20  23:48:03       200  1037650963476172800   mrfib011235813   \n",
       "3       2021-02-20  23:47:55       200           1556630828       redneurons   \n",
       "4       2021-02-20  23:47:38       200   816835464728604673   electricjesus_   \n",
       "...            ...       ...       ...                  ...              ...   \n",
       "126820  2021-02-16  18:21:24       200  1354817195902033929  juanpab06662684   \n",
       "126821  2021-02-16  18:21:24       200           3182022667      dig_deeper1   \n",
       "126822  2021-02-16  18:21:24       200   836754254861856768  drowningrockets   \n",
       "126823  2021-02-16  18:21:24       200  1333857184074043392          2goodhz   \n",
       "126824  2021-02-16  18:21:24       200  1346885101297291264       sk61693745   \n",
       "\n",
       "                                   name place  ... geo source user_rt_id  \\\n",
       "0                               Ryan ‚öæÔ∏è   NaN  ... NaN    NaN        NaN   \n",
       "1                     Inma Serrano üá™üá∏üïäüåç   NaN  ... NaN    NaN        NaN   \n",
       "2                       MrFib 011235813   NaN  ... NaN    NaN        NaN   \n",
       "3       Ko…ói üêå #FarmersProtest #EndSARS   NaN  ... NaN    NaN        NaN   \n",
       "4                Matthew Raymond Julian   NaN  ... NaN    NaN        NaN   \n",
       "...                                 ...   ...  ...  ..    ...        ...   \n",
       "126820                       juan pablo   NaN  ... NaN    NaN        NaN   \n",
       "126821                  Carlos Gonzalez   NaN  ... NaN    NaN        NaN   \n",
       "126822                          Icylder   NaN  ... NaN    NaN        NaN   \n",
       "126823                          2goodhz   NaN  ... NaN    NaN        NaN   \n",
       "126824                               SK   NaN  ... NaN    NaN        NaN   \n",
       "\n",
       "       user_rt retweet_id                                           reply_to  \\\n",
       "0          NaN        NaN  [{'screen_name': 'NaeimKhanjani', 'name': 'Nae...   \n",
       "1          NaN        NaN  [{'screen_name': 'ReinaldoDMM', 'name': 'Reina...   \n",
       "2          NaN        NaN                                                 []   \n",
       "3          NaN        NaN  [{'screen_name': 'TheAfricaReport', 'name': 'T...   \n",
       "4          NaN        NaN                                                 []   \n",
       "...        ...        ...                                                ...   \n",
       "126820     NaN        NaN  [{'screen_name': 'elonmusk', 'name': 'Elon Mus...   \n",
       "126821     NaN        NaN  [{'screen_name': 'LunchWithElon', 'name': 'Hri...   \n",
       "126822     NaN        NaN  [{'screen_name': 'elonmusk', 'name': 'Elon Mus...   \n",
       "126823     NaN        NaN  [{'screen_name': 'elonmusk', 'name': 'Elon Mus...   \n",
       "126824     NaN        NaN  [{'screen_name': 'Tesla', 'name': 'Tesla', 'id...   \n",
       "\n",
       "        retweet_date  translate trans_src trans_dest  \n",
       "0                NaN        NaN       NaN        NaN  \n",
       "1                NaN        NaN       NaN        NaN  \n",
       "2                NaN        NaN       NaN        NaN  \n",
       "3                NaN        NaN       NaN        NaN  \n",
       "4                NaN        NaN       NaN        NaN  \n",
       "...              ...        ...       ...        ...  \n",
       "126820           NaN        NaN       NaN        NaN  \n",
       "126821           NaN        NaN       NaN        NaN  \n",
       "126822           NaN        NaN       NaN        NaN  \n",
       "126823           NaN        NaN       NaN        NaN  \n",
       "126824           NaN        NaN       NaN        NaN  \n",
       "\n",
       "[126825 rows x 36 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 126825 entries, 0 to 126824\n",
      "Data columns (total 36 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   id               126825 non-null  int64  \n",
      " 1   conversation_id  126825 non-null  int64  \n",
      " 2   created_at       126825 non-null  object \n",
      " 3   date             126825 non-null  object \n",
      " 4   time             126825 non-null  object \n",
      " 5   timezone         126825 non-null  int64  \n",
      " 6   user_id          126825 non-null  int64  \n",
      " 7   username         126825 non-null  object \n",
      " 8   name             126822 non-null  object \n",
      " 9   place            52 non-null      object \n",
      " 10  tweet            126825 non-null  object \n",
      " 11  language         126825 non-null  object \n",
      " 12  mentions         126825 non-null  object \n",
      " 13  urls             126825 non-null  object \n",
      " 14  photos           126825 non-null  object \n",
      " 15  replies_count    126825 non-null  int64  \n",
      " 16  retweets_count   126825 non-null  int64  \n",
      " 17  likes_count      126825 non-null  int64  \n",
      " 18  hashtags         126825 non-null  object \n",
      " 19  cashtags         126825 non-null  object \n",
      " 20  link             126825 non-null  object \n",
      " 21  retweet          126825 non-null  bool   \n",
      " 22  quote_url        6524 non-null    object \n",
      " 23  video            126825 non-null  int64  \n",
      " 24  thumbnail        15502 non-null   object \n",
      " 25  near             0 non-null       float64\n",
      " 26  geo              0 non-null       float64\n",
      " 27  source           0 non-null       float64\n",
      " 28  user_rt_id       0 non-null       float64\n",
      " 29  user_rt          0 non-null       float64\n",
      " 30  retweet_id       0 non-null       float64\n",
      " 31  reply_to         126825 non-null  object \n",
      " 32  retweet_date     0 non-null       float64\n",
      " 33  translate        0 non-null       float64\n",
      " 34  trans_src        0 non-null       float64\n",
      " 35  trans_dest       0 non-null       float64\n",
      "dtypes: bool(1), float64(10), int64(8), object(17)\n",
      "memory usage: 34.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>timezone</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-20 23:48:03 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>To think of #Bitcoin as just a currency is to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-20 23:47:55 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>@TheAfricaReport @Tesla Look at the environmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-20 23:47:38 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>@GM #supercruise is NOT better than @Tesla ORI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-02-20 23:47:37 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>@JolivetRaphael @vgrichina @philiprosedale @Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-20 23:47:15 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>@CtTesla @OwenSparks_ @elonmusk @Tesla It was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126819</th>\n",
       "      <td>2021-02-16 18:21:25 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>@elonmusk @Tesla What about Dogecoin, chief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126821</th>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>@LunchWithElon @elonmusk @Tesla Just ask him t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126822</th>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>@elonmusk @Tesla Can you speak to the blackout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126823</th>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>@elonmusk @Tesla Careful of the black ice. Not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126824</th>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>@Tesla @elonmusk Looks like a key</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83688 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     created_at  timezone language  \\\n",
       "2       2021-02-20 23:48:03 IST       200       en   \n",
       "3       2021-02-20 23:47:55 IST       200       en   \n",
       "4       2021-02-20 23:47:38 IST       200       en   \n",
       "5       2021-02-20 23:47:37 IST       200       en   \n",
       "7       2021-02-20 23:47:15 IST       200       en   \n",
       "...                         ...       ...      ...   \n",
       "126819  2021-02-16 18:21:25 IST       200       en   \n",
       "126821  2021-02-16 18:21:24 IST       200       en   \n",
       "126822  2021-02-16 18:21:24 IST       200       en   \n",
       "126823  2021-02-16 18:21:24 IST       200       en   \n",
       "126824  2021-02-16 18:21:24 IST       200       en   \n",
       "\n",
       "                                                     text  \n",
       "2       To think of #Bitcoin as just a currency is to ...  \n",
       "3       @TheAfricaReport @Tesla Look at the environmen...  \n",
       "4       @GM #supercruise is NOT better than @Tesla ORI...  \n",
       "5       @JolivetRaphael @vgrichina @philiprosedale @Pa...  \n",
       "7       @CtTesla @OwenSparks_ @elonmusk @Tesla It was ...  \n",
       "...                                                   ...  \n",
       "126819        @elonmusk @Tesla What about Dogecoin, chief  \n",
       "126821  @LunchWithElon @elonmusk @Tesla Just ask him t...  \n",
       "126822  @elonmusk @Tesla Can you speak to the blackout...  \n",
       "126823  @elonmusk @Tesla Careful of the black ice. Not...  \n",
       "126824                  @Tesla @elonmusk Looks like a key  \n",
       "\n",
       "[83688 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['created_at','timezone','tweet','language']]\n",
    "df = df[df[\"language\"] == \"en\"]\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df[\"text\"] = df[\"tweet\"]\n",
    "df.drop(columns=['tweet'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83688/83688 [00:00<00:00, 173236.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2         To think of Bitcoin as just a currency is to t...\n",
       "3                           Look at the environmental cost.\n",
       "4         supercruise is NOT better than  ORIGINAL autop...\n",
       "5         Do you think the high energy use of the dept o...\n",
       "7         It was so good to have you with us, and thank ...\n",
       "                                ...                        \n",
       "126819                           What about Dogecoin, chief\n",
       "126821    Just ask him the questions through here. His t...\n",
       "126822    Can you speak to the blackouts in Texas? Peopl...\n",
       "126823    Careful of the black ice. Not worth driving on...\n",
       "126824                                     Looks like a key\n",
       "Name: text, Length: 83688, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_up_tweet(txt):\n",
    "    # Remove mentions\n",
    "    txt = re.sub(r'@[A-Za-z0-9_]+', '', txt)\n",
    "    # Remove hashtags\n",
    "    txt = re.sub(r'#', '', txt)\n",
    "    # Remove retweets:\n",
    "    txt = re.sub(r'RT : ', '', txt)\n",
    "    # Remove urls\n",
    "    txt = re.sub(r'https?:\\/\\/[A-Za-z0-9\\.\\/]+', '', txt).strip()\n",
    "    return txt\n",
    "\n",
    "df[\"text\"] = df[\"text\"].progress_apply(clean_up_tweet)\n",
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_insults(tweet):\n",
    "    return re.sub(r\"(\\*){3,}\\*\", \"-INSULT-\", tweet).strip()\n",
    "\n",
    "df[\"text\"] = df[\"text\"].progress_apply(lemmatize_insults)\n",
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83688/83688 [00:00<00:00, 97253.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2         To think of Bitcoin as just a currency is to t...\n",
       "3                           Look at the environmental cost.\n",
       "4         supercruise is NOT better than  ORIGINAL autop...\n",
       "5         Do you think the high energy use of the dept o...\n",
       "7         It was so good to have you with us, and thank ...\n",
       "                                ...                        \n",
       "126819                           What about Dogecoin, chief\n",
       "126821    Just ask him the questions through here. His t...\n",
       "126822    Can you speak to the blackouts in Texas? Peopl...\n",
       "126823    Careful of the black ice. Not worth driving on...\n",
       "126824                                     Looks like a key\n",
       "Name: text, Length: 83688, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_contractions(phrase):\n",
    "    phrase = re.sub(r\"\\`\", \"\\'\", phrase)\n",
    "    \n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase.strip()\n",
    "\n",
    "df[\"text\"] = df[\"text\"].progress_apply(expand_contractions)\n",
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83688/83688 [00:00<00:00, 212608.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2         To think of Bitcoin as just a currency is to t...\n",
       "3                           Look at the environmental cost.\n",
       "4         supercruise is NOT better than  ORIGINAL autop...\n",
       "5         Do you think the high energy use of the dept o...\n",
       "7         It was so good to have you with us, and thank ...\n",
       "                                ...                        \n",
       "126819                           What about Dogecoin, chief\n",
       "126821    Just ask him the questions through here. His t...\n",
       "126822    Can you speak to the blackouts in Texas? Peopl...\n",
       "126823    Careful of the black ice. Not worth driving on...\n",
       "126824                                     Looks like a key\n",
       "Name: text, Length: 83688, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text).strip()\n",
    "\n",
    "df[\"text\"] = df[\"text\"].progress_apply(deEmojify)\n",
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83688/83688 [00:01<00:00, 58828.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2         To think of Bitcoin as just a currency is to t...\n",
       "3                           Look at the environmental cost.\n",
       "4         supercruise is NOT better than  ORIGINAL autop...\n",
       "5         Do you think the high energy use of the dept o...\n",
       "7         It was so good to have you with us, and thank ...\n",
       "                                ...                        \n",
       "126819                           What about Dogecoin, chief\n",
       "126821    Just ask him the questions through here. His t...\n",
       "126822    Can you speak to the blackouts in Texas? Peopl...\n",
       "126823    Careful of the black ice. Not worth driving on...\n",
       "126824                                     Looks like a key\n",
       "Name: text, Length: 83688, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_numbers(tweet):\n",
    "    return re.sub(r'\\w*\\d\\w*', \"\", tweet).strip()\n",
    "\n",
    "df[\"text\"] = df[\"text\"].progress_apply(remove_numbers)\n",
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tweet(tweet):\n",
    "    lemmatized_text = nlp(tweet)\n",
    "    lemmatized_text_lst = [word.lemma_ for word in lemmatized_text]\n",
    "    return \" \".join(lemmatized_text_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83688/83688 [11:11<00:00, 124.55it/s]\n"
     ]
    }
   ],
   "source": [
    "df[\"text\"] = df[\"text\"].progress_apply(lemmatize_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>timezone</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-20 23:48:03 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>to think of Bitcoin as just a currency be to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-20 23:47:55 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>look at the environmental cost .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-20 23:47:38 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>supercruise be not well than   original autopi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-02-20 23:47:37 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>do -PRON- think the high energy use of the dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-20 23:47:15 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>-PRON- be so good to have -PRON- with -PRON- ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126819</th>\n",
       "      <td>2021-02-16 18:21:25 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>what about Dogecoin , chief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126821</th>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>just ask -PRON- the question through here . -P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126822</th>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>Can -PRON- speak to the blackout in Texas ? Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126823</th>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>careful of the black ice . not worth drive on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126824</th>\n",
       "      <td>2021-02-16 18:21:24 IST</td>\n",
       "      <td>200</td>\n",
       "      <td>en</td>\n",
       "      <td>look like a key</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83684 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     created_at  timezone language  \\\n",
       "2       2021-02-20 23:48:03 IST       200       en   \n",
       "3       2021-02-20 23:47:55 IST       200       en   \n",
       "4       2021-02-20 23:47:38 IST       200       en   \n",
       "5       2021-02-20 23:47:37 IST       200       en   \n",
       "7       2021-02-20 23:47:15 IST       200       en   \n",
       "...                         ...       ...      ...   \n",
       "126819  2021-02-16 18:21:25 IST       200       en   \n",
       "126821  2021-02-16 18:21:24 IST       200       en   \n",
       "126822  2021-02-16 18:21:24 IST       200       en   \n",
       "126823  2021-02-16 18:21:24 IST       200       en   \n",
       "126824  2021-02-16 18:21:24 IST       200       en   \n",
       "\n",
       "                                                     text  \n",
       "2       to think of Bitcoin as just a currency be to t...  \n",
       "3                        look at the environmental cost .  \n",
       "4       supercruise be not well than   original autopi...  \n",
       "5       do -PRON- think the high energy use of the dep...  \n",
       "7       -PRON- be so good to have -PRON- with -PRON- ,...  \n",
       "...                                                   ...  \n",
       "126819                        what about Dogecoin , chief  \n",
       "126821  just ask -PRON- the question through here . -P...  \n",
       "126822  Can -PRON- speak to the blackout in Texas ? Pe...  \n",
       "126823  careful of the black ice . not worth drive on ...  \n",
       "126824                                    look like a key  \n",
       "\n",
       "[83684 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.to_csv(\"lemmatized_tesla_tweets_df.csv\")\n",
    "df = pd.read_csv('lemmatized_tesla_tweets_df.csv', index_col=0).dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 83684/83684 [00:00<00:00, 197613.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def remove_punctuation(tweet):\n",
    "    tweet = re.sub(f\"[{punctuation}]\", \"\", tweet).strip()\n",
    "    return tweet\n",
    "\n",
    "df[\"text\"] = df[\"text\"].progress_apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2         to think of Bitcoin as just a currency be to t...\n",
       "3                            look at the environmental cost\n",
       "4         supercruise be not well than   original autopi...\n",
       "5         do PRON think the high energy use of the dept ...\n",
       "7         PRON be so good to have PRON with PRON  and th...\n",
       "                                ...                        \n",
       "126819                           what about Dogecoin  chief\n",
       "126821    just ask PRON the question through here  PRON ...\n",
       "126822    Can PRON speak to the blackout in Texas  Peopl...\n",
       "126823    careful of the black ice  not worth drive on y...\n",
       "126824                                      look like a key\n",
       "Name: text, Length: 83684, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['.', 'A.S.S', 'as', 'for', 'know', 'otherwise', 'short'],\n",
       "       dtype='<U9'),\n",
       " array([1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df.loc[20, \"text\"].split(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danielsiles/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1,3), min_df=25, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TARGET' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-aa2f178a2dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TARGET' is not defined"
     ]
    }
   ],
   "source": [
    "def sentiment_encoder(sentiment):\n",
    "    if sentiment == 'negative':\n",
    "        return 0\n",
    "    elif sentiment == 'neutral':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df[TARGET] = df[TARGET].apply(sentiment_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "# from wordcloud import WordCloud\n",
    "\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Create a function to get the polarity\n",
    "def getPolarity(text):\n",
    "    return  TextBlob(text).sentiment.polarity\n",
    "\n",
    "\n",
    "# Create two new columns 'Subjectivity' & 'Polarity'\n",
    "df['Subjectivity'] = df['text'].apply(getSubjectivity)\n",
    "df['Polarity'] = df['text'].apply(getPolarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(TARGET, axis=1)\n",
    "y = df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (24728, 1)\n",
      "X_test shape: (2748, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = vectorizer.fit_transform(X_train[\"text\"])\n",
    "X_test_vectorized = vectorizer.transform(X_test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_vectorized shape: (24728, 1419)\n",
      "X_test_vectorized shape: (2748, 1419)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_vectorized shape:\", X_train_vectorized.shape)\n",
    "print(\"X_test_vectorized shape:\", X_test_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = pd.concat([pd.DataFrame(X_train_vectorized.toarray(), index=X_train.index), X_train.drop(\"text\",axis=1)], axis=1)\n",
    "X_test_t = pd.concat([pd.DataFrame(X_test_vectorized.toarray(), index=X_test.index), X_test.drop(\"text\",axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (24728, 1419)\n",
      "X_test shape: (2748, 1419)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train_t.shape)\n",
    "print(\"X_test shape:\", X_test_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-1f309d94dc61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;34m\"not %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 self.label_binarizer_.classes_[i]])\n\u001b[0;32m--> 245\u001b[0;31m             for i, column in enumerate(columns))\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/multiclass.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[0;34m(estimator, X, y, classes)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mcc = OneVsRestClassifier(SVC(verbose=1))\n",
    "mcc.fit(X_train_t, y_train)\n",
    "y_pred = mcc.predict(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "mcc = OneVsRestClassifier(GaussianNB())\n",
    "mcc.fit(X_train_t, y_train)\n",
    "y_pred = mcc.predict(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LogisticRegression(penalty=\"l1\", solver=\"saga\", C=10, max_iter=100000)\n",
    "lin_reg.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_reg.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
